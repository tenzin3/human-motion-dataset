{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f96d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "with open(\"motion_mapping.json\", \"r\") as f:\n",
    "    mocap_data = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "046ddf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk samples: 258\n",
      "Run samples: 75\n",
      "Jump samples: 102\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define keyword lists\n",
    "walk_keywords = ['walk', 'walking', 'wander', 'stride', 'pacing', 'march', 'limp', 'mope']\n",
    "run_keywords = ['run', 'running', 'jog', 'jogging', 'scramble']\n",
    "jump_keywords = ['jump', 'jumping', 'hop', 'hopping', 'leap', 'jete', 'skip', 'bound']\n",
    "\n",
    "# Initialize datasets\n",
    "walk_dataset = {}\n",
    "run_dataset = {}\n",
    "jump_dataset = {}\n",
    "\n",
    "for description, ids in mocap_data.items():\n",
    "    desc_lower = description.lower()\n",
    "    \n",
    "    # Check for Walk\n",
    "    if any(k in desc_lower for k in walk_keywords):\n",
    "        walk_dataset[description] = ids\n",
    "        \n",
    "    # Check for Run\n",
    "    if any(k in desc_lower for k in run_keywords):\n",
    "        run_dataset[description] = ids\n",
    "        \n",
    "    # Check for Jump\n",
    "    if any(k in desc_lower for k in jump_keywords):\n",
    "        jump_dataset[description] = ids\n",
    "\n",
    "# Example output\n",
    "print(f\"Walk samples: {len(walk_dataset)}\")\n",
    "print(f\"Run samples: {len(run_dataset)}\")\n",
    "print(f\"Jump samples: {len(jump_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e6d06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from typing import Optional, List\n",
    "from bvh import Bvh\n",
    "\n",
    "def convert(\n",
    "    bvh_path: str,\n",
    "    out_csv_path: Optional[str] = None,\n",
    "    *,\n",
    "    drop_tpose_frame0: bool = True,      # CMU/cgspeed release adds a T-pose at frame 0\n",
    "    downsample: int = 1,                 # e.g., 4 keeps every 4th frame\n",
    "    rotations_to_radians: bool = False,  # BVH rotations are in degrees\n",
    "    dtype=np.float32\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Load a BVH file, apply basic preprocessing, and save a CSV.\n",
    "\n",
    "    Preprocessing included:\n",
    "      - Optional removal of frame 0 (T-pose) commonly added by the CMU/cgspeed conversion.\n",
    "      - Optional temporal downsampling.\n",
    "      - Optional degree->radian conversion for rotation channels (keeps positions unchanged).\n",
    "\n",
    "    The CSV columns are ordered exactly as BVH channels appear (HIERARCHY traversal order).\n",
    "    Column names are generated as: \"{JointName}_{ChannelName}\" (e.g., \"Hips_Xposition\").\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Parse BVH ---\n",
    "    with open(bvh_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        mocap = Bvh(f.read())\n",
    "\n",
    "    # Frames: list[list[str]] where each inner list is all channel values for that frame\n",
    "    frames = mocap.frames\n",
    "    if frames is None or len(frames) == 0:\n",
    "        raise ValueError(f\"No MOTION frames found in: {bvh_path}\")\n",
    "\n",
    "    data = np.asarray(frames, dtype=dtype)  # shape: (T, D)\n",
    "\n",
    "    # --- Build column names (channel order must match mocap.frames order) ---\n",
    "    # The 'bvh' library keeps joints in file order, so we reproduce that:\n",
    "    joint_names = mocap.get_joints_names()\n",
    "\n",
    "    col_names: List[str] = []\n",
    "    for j in joint_names:\n",
    "        chans = mocap.joint_channels(j)  # e.g., ['Xposition','Yposition','Zposition','Zrotation','Yrotation','Xrotation']\n",
    "        for ch in chans:\n",
    "            col_names.append(f\"{j}_{ch}\")\n",
    "\n",
    "    # Sanity check: columns must match data width\n",
    "    if len(col_names) != data.shape[1]:\n",
    "        # Fallback: still save, but with generic names if mismatch occurs\n",
    "        col_names = [f\"dim_{i}\" for i in range(data.shape[1])]\n",
    "\n",
    "    # --- Preprocess ---\n",
    "    # 1) Drop frame 0 T-pose if desired (CMU/cgspeed: \"T pose is in frame 0\")\n",
    "    if drop_tpose_frame0 and data.shape[0] > 1:\n",
    "        data = data[1:, :]\n",
    "\n",
    "    # 2) Downsample\n",
    "    if downsample is not None and int(downsample) > 1:\n",
    "        ds = int(downsample)\n",
    "        data = data[::ds, :]\n",
    "\n",
    "    # 3) Convert rotation channels to radians (positions unchanged)\n",
    "    if rotations_to_radians:\n",
    "        rot_mask = np.array([name.endswith(\"_Xrotation\") or\n",
    "                             name.endswith(\"_Yrotation\") or\n",
    "                             name.endswith(\"_Zrotation\") for name in col_names], dtype=bool)\n",
    "        data[:, rot_mask] = np.deg2rad(data[:, rot_mask])\n",
    "\n",
    "    # --- Save CSV ---\n",
    "    os.makedirs(os.path.dirname(out_csv_path) or \".\", exist_ok=True)\n",
    "\n",
    "    with open(out_csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(col_names)\n",
    "        writer.writerows(data.tolist())\n",
    "\n",
    "    return out_csv_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2baf77d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting walking: 100%|██████████| 258/258 [01:20<00:00,  3.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save dataset as .csv in new directory 'walk', 'run', 'jump'\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "for key, file_ids in tqdm(walk_dataset.items(), desc=\"Converting walking\"):\n",
    "    for file_id in file_ids:\n",
    "\n",
    "        dir_number = file_id.split('_')[0]\n",
    "        \n",
    "        if len(dir_number) == 1:\n",
    "            dir_number = f\"00{dir_number}\"\n",
    "        elif len(dir_number) == 2:\n",
    "            dir_number = f\"0{dir_number}\"\n",
    "        \n",
    "        bvh_file = f\"data/{dir_number}/{file_id}.bvh\"\n",
    "        out_csv_path = f\"walk/{file_id}.csv\"\n",
    "        convert(str(bvh_file), out_csv_path=out_csv_path, downsample=4, drop_tpose_frame0=True, rotations_to_radians=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "567fb0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting walking: 100%|██████████| 75/75 [00:09<00:00,  7.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save dataset as .csv in new directory 'walk', 'run', 'jump'\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "for key, file_ids in tqdm(run_dataset.items(), desc=\"Converting walking\"):\n",
    "    for file_id in file_ids:\n",
    "\n",
    "        dir_number = file_id.split('_')[0]\n",
    "        \n",
    "        if len(dir_number) == 1:\n",
    "            dir_number = f\"00{dir_number}\"\n",
    "        elif len(dir_number) == 2:\n",
    "            dir_number = f\"0{dir_number}\"\n",
    "        \n",
    "        bvh_file = f\"data/{dir_number}/{file_id}.bvh\"\n",
    "        out_csv_path = f\"run/{file_id}.csv\"\n",
    "        convert(str(bvh_file), out_csv_path=out_csv_path, downsample=4, drop_tpose_frame0=True, rotations_to_radians=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9052c5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting walking: 100%|██████████| 102/102 [00:20<00:00,  5.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save dataset as .csv in new directory 'walk', 'run', 'jump'\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "for key, file_ids in tqdm(jump_dataset.items(), desc=\"Converting walking\"):\n",
    "    for file_id in file_ids:\n",
    "\n",
    "        dir_number = file_id.split('_')[0]\n",
    "        \n",
    "        if len(dir_number) == 1:\n",
    "            dir_number = f\"00{dir_number}\"\n",
    "        elif len(dir_number) == 2:\n",
    "            dir_number = f\"0{dir_number}\"\n",
    "        \n",
    "        bvh_file = f\"data/{dir_number}/{file_id}.bvh\"\n",
    "        out_csv_path = f\"jump/{file_id}.csv\"\n",
    "        convert(str(bvh_file), out_csv_path=out_csv_path, downsample=4, drop_tpose_frame0=True, rotations_to_radians=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b239c9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets saved to walk_run_jump_datasets.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Combine datasets into one dictionary\n",
    "combined_data = {\n",
    "    \"walk\": walk_dataset,\n",
    "    \"run\": run_dataset,\n",
    "    \"jump\": jump_dataset\n",
    "}\n",
    "\n",
    "# Save to a JSON file\n",
    "output_path = \"walk_run_jump_datasets.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(combined_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Datasets saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144d235c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
