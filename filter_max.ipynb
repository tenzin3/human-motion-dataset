{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83b76d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "with open(\"motion_mapping.json\", \"r\") as f:\n",
    "    mocap_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70c1d109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk samples: 94\n",
      "Run samples: 26\n",
      "Jump samples: 36\n"
     ]
    }
   ],
   "source": [
    "walk_dataset = mocap_data[\"walk\"]\n",
    "run_dataset = mocap_data[\"run\"]\n",
    "jump_dataset = mocap_data[\"jump\"]\n",
    "\n",
    "\n",
    "print(f\"Walk samples: {len(walk_dataset)}\")\n",
    "print(f\"Run samples: {len(run_dataset)}\")\n",
    "print(f\"Jump samples: {len(jump_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18db1cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from typing import Optional, List\n",
    "from bvh import Bvh\n",
    "\n",
    "def convert(\n",
    "    bvh_path: str,\n",
    "    out_csv_path: Optional[str] = None,\n",
    "    *,\n",
    "    drop_tpose_frame0: bool = True,      # CMU/cgspeed release adds a T-pose at frame 0\n",
    "    downsample: int = 1,                 # e.g., 4 keeps every 4th frame\n",
    "    rotations_to_radians: bool = False,  # BVH rotations are in degrees\n",
    "    dtype=np.float32\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Load a BVH file, apply basic preprocessing, and save a CSV.\n",
    "\n",
    "    Preprocessing included:\n",
    "      - Optional removal of frame 0 (T-pose) commonly added by the CMU/cgspeed conversion.\n",
    "      - Optional temporal downsampling.\n",
    "      - Optional degree->radian conversion for rotation channels (keeps positions unchanged).\n",
    "\n",
    "    The CSV columns are ordered exactly as BVH channels appear (HIERARCHY traversal order).\n",
    "    Column names are generated as: \"{JointName}_{ChannelName}\" (e.g., \"Hips_Xposition\").\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Parse BVH ---\n",
    "    with open(bvh_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        mocap = Bvh(f.read())\n",
    "\n",
    "    # Frames: list[list[str]] where each inner list is all channel values for that frame\n",
    "    frames = mocap.frames\n",
    "    if frames is None or len(frames) == 0:\n",
    "        raise ValueError(f\"No MOTION frames found in: {bvh_path}\")\n",
    "\n",
    "    data = np.asarray(frames, dtype=dtype)  # shape: (T, D)\n",
    "\n",
    "    # --- Build column names (channel order must match mocap.frames order) ---\n",
    "    # The 'bvh' library keeps joints in file order, so we reproduce that:\n",
    "    joint_names = mocap.get_joints_names()\n",
    "\n",
    "    col_names: List[str] = []\n",
    "    for j in joint_names:\n",
    "        chans = mocap.joint_channels(j)  # e.g., ['Xposition','Yposition','Zposition','Zrotation','Yrotation','Xrotation']\n",
    "        for ch in chans:\n",
    "            col_names.append(f\"{j}_{ch}\")\n",
    "\n",
    "    # Sanity check: columns must match data width\n",
    "    if len(col_names) != data.shape[1]:\n",
    "        # Fallback: still save, but with generic names if mismatch occurs\n",
    "        col_names = [f\"dim_{i}\" for i in range(data.shape[1])]\n",
    "\n",
    "    # --- Preprocess ---\n",
    "    # 1) Drop frame 0 T-pose if desired (CMU/cgspeed: \"T pose is in frame 0\")\n",
    "    if drop_tpose_frame0 and data.shape[0] > 1:\n",
    "        data = data[1:, :]\n",
    "\n",
    "    # 2) Downsample\n",
    "    if downsample is not None and int(downsample) > 1:\n",
    "        ds = int(downsample)\n",
    "        data = data[::ds, :]\n",
    "\n",
    "    # 3) Convert rotation channels to radians (positions unchanged)\n",
    "    if rotations_to_radians:\n",
    "        rot_mask = np.array([name.endswith(\"_Xrotation\") or\n",
    "                             name.endswith(\"_Yrotation\") or\n",
    "                             name.endswith(\"_Zrotation\") for name in col_names], dtype=bool)\n",
    "        data[:, rot_mask] = np.deg2rad(data[:, rot_mask])\n",
    "\n",
    "    # --- Save CSV ---\n",
    "    os.makedirs(os.path.dirname(out_csv_path) or \".\", exist_ok=True)\n",
    "\n",
    "    with open(out_csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(col_names)\n",
    "        writer.writerows(data.tolist())\n",
    "\n",
    "    return out_csv_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffc0f897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting walking:   0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting walking: 100%|██████████| 94/94 [00:04<00:00, 22.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save dataset as .csv in new directory 'walk', 'run', 'jump'\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for file_id in tqdm(walk_dataset, desc=\"Converting walking\"):\n",
    "\n",
    "    dir_number = file_id.split('_')[0]\n",
    "    \n",
    "    if len(dir_number) == 1:\n",
    "        dir_number = f\"00{dir_number}\"\n",
    "    elif len(dir_number) == 2:\n",
    "        dir_number = f\"0{dir_number}\"\n",
    "    \n",
    "    bvh_file = f\"data/{dir_number}/{file_id}.bvh\"\n",
    "    out_csv_path = f\"walk_only/{file_id}.csv\"\n",
    "    convert(str(bvh_file), out_csv_path=out_csv_path, downsample=4, drop_tpose_frame0=True, rotations_to_radians=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "378ef13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting running: 100%|██████████| 26/26 [00:00<00:00, 49.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save dataset as .csv in new directory 'walk', 'run', 'jump'\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for file_id in tqdm(run_dataset, desc=\"Converting running\"):\n",
    "\n",
    "    dir_number = file_id.split('_')[0]\n",
    "    \n",
    "    if len(dir_number) == 1:\n",
    "        dir_number = f\"00{dir_number}\"\n",
    "    elif len(dir_number) == 2:\n",
    "        dir_number = f\"0{dir_number}\"\n",
    "    \n",
    "    bvh_file = f\"data/{dir_number}/{file_id}.bvh\"\n",
    "    out_csv_path = f\"run_only/{file_id}.csv\"\n",
    "    convert(str(bvh_file), out_csv_path=out_csv_path, downsample=4, drop_tpose_frame0=True, rotations_to_radians=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9974cd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting jumping: 100%|██████████| 36/36 [00:01<00:00, 25.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save dataset as .csv in new directory 'walk', 'run', 'jump'\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for file_id in tqdm(jump_dataset, desc=\"Converting jumping\"):\n",
    "\n",
    "    dir_number = file_id.split('_')[0]\n",
    "    \n",
    "    if len(dir_number) == 1:\n",
    "        dir_number = f\"00{dir_number}\"\n",
    "    elif len(dir_number) == 2:\n",
    "        dir_number = f\"0{dir_number}\"\n",
    "    \n",
    "    bvh_file = f\"data/{dir_number}/{file_id}.bvh\"\n",
    "    out_csv_path = f\"jump_only/{file_id}.csv\"\n",
    "    convert(str(bvh_file), out_csv_path=out_csv_path, downsample=4, drop_tpose_frame0=True, rotations_to_radians=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b81b3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
